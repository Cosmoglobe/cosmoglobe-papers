\documentclass[twocolumn]{../common/aa}
%\documentclass[referee]{aa}

\usepackage{graphicx}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{txfonts}
\usepackage{color}
\usepackage{natbib}
\usepackage{float}
%\usepackage{stfloats}
\usepackage{dblfloatfix}
\usepackage{afterpage}
\usepackage{ifthen}
\usepackage[morefloats=12]{morefloats}
\usepackage{placeins}
\usepackage{multicol}
\bibpunct{(}{)}{;}{a}{}{,}
\usepackage[switch]{lineno}
\definecolor{linkcolor}{rgb}{0.6,0,0}
\definecolor{citecolor}{rgb}{0,0,0.75}
\definecolor{urlcolor}{rgb}{0.12,0.46,0.7}
\usepackage[breaklinks, colorlinks, urlcolor=urlcolor,
    linkcolor=linkcolor,citecolor=citecolor,pdfencoding=auto]{hyperref}
\hypersetup{linktocpage}
\usepackage{bold-extra}
\usepackage{xcolor}

%\usepackage[grid,
%  gridcolor=red!20,
%  subgridcolor=green!20,
%  gridunit=cm]{eso-pic}
%

\input{../common/Planck}

\def\WMAP{\emph{WMAP}}
\def\WMAPnine{\emph{WMAP9}}
\def\COBE{\emph{COBE}}
\def\wmap{\emph{WMAP}}
\def\planck{\emph{Planck}}
\def\Planck{\emph{Planck}}
\def\LCDM{$\Lambda$CDM}
\def\ffp{FFP6}
\def\unionmask{U73}
\def\nside{N_{\mathrm{side}}}

\def\healpix{\texttt{HEALPix}}
\def\commander{\texttt{Commander}}
\def\commanderone{\texttt{Commander1}}
\def\commandertwo{\texttt{Commander2}}
\def\commanderthree{\texttt{Commander3}}
\def\ruler{\texttt{Ruler}}
\def\comrul{\texttt{Commander-Ruler}}
\def\CR{\texttt{C-R}}
\def\nilc{\texttt{NILC}}
\def\gnilc{\texttt{GNILC}}
\def\sevem{\texttt{SEVEM}}
\def\smica{\texttt{SMICA}}
\def\CamSpec{\texttt{CamSpec}}
\def\Plik{\texttt{Plik}}
\def\XFaster{\texttt{XFaster}}
\def\sroll2{\texttt{SRoll2}}

\renewcommand{\d}[0]{\vec{d}}
\renewcommand{\t}[0]{\vec{t}}
\newcommand{\A}[0]{\mathrm{A}}
\newcommand{\B}[0]{\mathrm{B}}
\newcommand{\Y}[0]{\tens{Y}}
\newcommand{\n}[0]{\vec{n}}
\newcommand{\red}[0]{\color{red}}
\newcommand{\green}[0]{\color{green}}
\newcommand{\s}[0]{\vec{s}}
\renewcommand{\a}[0]{\vec{a}}
\newcommand{\m}[0]{\vec{m}}
\newcommand{\f}[0]{\vec{f}}
\newcommand{\F}[0]{\tens{F}}
\newcommand{\T}[0]{\tens{T}}
\newcommand{\Cp}[0]{\tens{C}}
\renewcommand{\L}[0]{\tens{L}}
\newcommand{\g}[0]{\vec{g}}
\newcommand{\N}[0]{\tens{N}}
\newcommand{\M}[0]{\tens{M}}
\newcommand{\iN}[0]{\tens{N}^{-1}}
\newcommand{\iM}[0]{\tens{M}^{-1}}
\newcommand{\w}[0]{\vec{w}}
\renewcommand{\S}[0]{\tens{S}}
\renewcommand{\r}[0]{\vec{r}}
\renewcommand{\u}[0]{\vec{u}}
\newcommand{\q}[0]{\vec{q}}
\renewcommand{\v}[0]{\vec{v}}
\renewcommand{\P}[0]{\tens{P}}
\newcommand{\dt}[0]{d_t}
\newcommand{\di}[0]{d_i}
\newcommand{\nt}[0]{n_t}
\newcommand{\st}[0]{s_t}
\newcommand{\mt}[0]{m_t}
\newcommand{\ft}[0]{f_t}
\newcommand{\Te}[0]{T_{\rm e}}
\newcommand{\EM}[0]{\rm EM}
\newcommand{\mathsc}[1]{{\normalfont\textsc{#1}}}
\newcommand{\hi}{\ensuremath{\mathsc {Hi}}}
\newcommand{\bpbold}{\bfseries{\scshape{BeyondPlanck}}}
\newcommand{\BP}{\textsc{BeyondPlanck}}
\newcommand{\bp}{\textsc{BeyondPlanck}}
\newcommand{\cosmoglobe}{\textsc{Cosmoglobe}}
\newcommand{\Cosmoglobe}{\textsc{Cosmoglobe}}
\newcommand{\lfi}[0]{LFI}
\newcommand{\hfi}[0]{HFI}
\newcommand{\npipe}[0]{\texttt{NPIPE}}
\newcommand{\K}[0]{\textit K}
\newcommand{\Ka}[0]{\textit{Ka}}
\newcommand{\Q}[0]{\textit Q}
\newcommand{\V}[0]{\textit V}
\newcommand{\W}[0]{\textit W}
\newcommand{\e}{\mathrm e}
\newcommand{\cvar}{\ensuremath{c(\vartheta, \varphi, \psi)}}


\def\bC{\tens{C}}
\def\ba{\vec{a}}
\def\ncha{N_\mathrm{cha}}
\def\nfg{N_\mathrm{fg}}

\newcommand{\ncorr}{\vec n_\mathrm{corr}}
\newcommand{\Dbp}{\Delta_\mathrm{bp}}

%\modulolinenumbers[5]
%\linenumbers

\newcommand{\includegraphicsdpi}[3]{
    \pdfimageresolution=#1  % Change the dpi of images
    \includegraphics[#2]{#3}
    \pdfimageresolution=72  % Change it back to the default
}

\renewcommand{\topfraction}{1.0}	% max fraction of floats at top
    \renewcommand{\bottomfraction}{1.0}	% max fraction of floats at bottom
    %   Parameters for TEXT pages (not float pages):
    \setcounter{topnumber}{2}
    \setcounter{bottomnumber}{2}
    \setcounter{totalnumber}{4}     % 2 may work better
    \setcounter{dbltopnumber}{2}    % for 2-column pages
    \renewcommand{\dbltopfraction}{0.9}	% fit big float above 2-col. text
    \renewcommand{\textfraction}{0.04}	% allow minimal text w. figs
    %   Parameters for FLOAT pages (not text pages):
    \renewcommand{\floatpagefraction}{0.9}	% require fuller float pages
	% N.B.: floatpagefraction MUST be less than topfraction !!
    \renewcommand{\dblfloatpagefraction}{0.9}	% require fuller float pages

\def\adj{^{\dagger}}
\def\tp{^{\rm T}}
\def\inv{^{-1}}
\def\lm{{\ell m}}

\begin{document}

\title{\bfseries{\Cosmoglobe: Assessing the computational costs of likelihood-free\\ cosmological parameter estimation with CMB data}}
\input{authors.tex}
%\authorrunning{From BeyondPlanck to Cosmoglobe}
\authorrunning{Eskilt et al.}
\titlerunning{CMB parameter estimation}

\abstract{
  We implement support for likelihood-free cosmological parameter estimation in \commanderthree, an integrated Bayesian analysis framework for cosmic microwave background (CMB) observations developed by the \BP\ and \cosmoglobe\ projects, and we assess the computational costs of this method. This method was originally proposed by Racine et al.\ (2016), who implemented a proof-of-concept Python code applicable to ideal observations with uniform white noise and full-sky coverage; with the new \commanderthree\ implementation presented in this paper, this method is now finally applicable to realistic data with full end-to-end error propagation. We validate the results with two external codes. The first is a uniform noise and full-sky likelihood likelihood coupled to Cobaya, and we find excellent agreement in this ideal case. The second code is a special-purpose Python implementation of the Racine et al.\ method for uniform noise and an azimuthally symmetric Galactic mask, for which the fundamental mapmaking equations may be solved analytically. We find good agreement also in this case, up to the precision allowed by the finite number of available samples. However, we also find that the computational cost of producing one single CMB sample with acceptable accuracy using the current implementation is high: For a case similar to the \Planck\ LFI 70\,GHz channel (with $\ell_{\mathrm{max}}=1300$, $N_\mathrm{side}=512$, and an accepted sky fraction of $f_{\mathrm{sky}}=0.85$), we require more than 5000 Conjugate Gradient iterations to reach sufficient accuracy, for a total computational cost of 2848\,CPU-hrs. At the same time, the typical Markov chain correlation length is $\sim$$\,100$ samples, and producing two indendent samples therefore costs $\sim$$\,30 000$\,CPU-hrs. For comparison, producing one single end-to-end sample for all \Planck\ LFI and \WMAP\ channels costs 812\,CPU-hrs, including calibration, mapmaking and component separation. Thus, for this method to be practical, future work should aim to reduce the cost per sample by at least one order of magnitude, which should be entirely feasible through the use of better multi-grid preconditioners and/or derivative-based hybrid sampling schemes.
}

\keywords{ISM: general -- Cosmology: observations, polarization,
    cosmic microwave background, diffuse radiation -- Galaxy:
    general}

\maketitle

%\hypersetup{linkcolor=black}
\tableofcontents
%\hypersetup{linkcolor=red} 




\section{Introduction}
\label{sec:introduction}

  High-precision cosmic microwave background (CMB) measurements provide today the strongest constraints on a wide range of key cosmological parameters. Traditionally, these constraints are derived by first compressing the information contained in the high-dimensional raw time-ordered data into pixelized sky maps and angular power spectra, and this compressed dataset is typically summarized in terms of a low-dimensional likelihood from which cosmological parameters are derived through Markov Chain Monte Carlo sampling. However, as the signal-to-noise ratio of the raw data continue to increase, the importance of systematic uncertainties grows, and these are often non-trivial to describe through a low-dimensional likelihood. To meet this challenge, the \BP\ and \cosmoglobe\ projects have implemented the world's first end-to-end Bayesian CMB framework.


\section{Joint sampling of cosmological parameters and sky signal}
\label{sec:methods}

In this section, we will introduce the algorithm proposed in \citet{racine:2016} to jointly sample the cosmological parameters of the CMB and its sky signal without using any likelihood approximations.

We define the data model as
\begin{equation}
    \label{eq:data_model}
    d_{\ell m} = A_{\ell} s_{\ell m} + n_{\ell m},
\end{equation}
in spherical harmonics space where $d_{\ell m}$ is the observed data, $A_\ell$ is the diagonal beam and pixel window functions. $s_{\ell m}$ is the Gaussian CMB signal and $n_{\ell m}$ is the Gaussian instrumental noise. Eq.~\eqref{eq:data_model} is equivalent in pixel space where $d_p = \sum_{\ell m} d_{\ell m} Y_{\ell m}$ with $p$ denoting the pixel and $Y_{\ell m}$ the spherical harmonics.

The covariance matrices are given as $\langle s_{\ell m}s_{\ell' m'}^* \rangle = C_{\ell} \delta_{\ell \ell'}\delta_{mm'}$ and $\langle n_{\ell m}n_{\ell' m'}^* \rangle = N_{\ell m, \ell' m'}$. With isotropic noise and no mask, $N_{\ell m, \ell' m'} $ becomes diagonal, i.e. $N_{\ell m, \ell' m'} = N_\ell \delta_{\ell \ell'}\delta_{mm'}$. But for a realistic setup with anisotropic instrumental noise and partial sky coverage, it will be non-diagonal and can be dense.

\subsection{Exact likelihood}
\label{sec:exact-likelihood}

In principle, we could evaluate the exact marginal likelihood of the cosmological parameters given the data, 
\begin{equation}
    P(\theta | \textbf{d}) \propto \frac{e^{-\frac12 \textbf{d}^T (\textbf{A}^T \textbf{S}(\theta) \textbf{A} + \textbf{N})^{-1}\textbf{d}}}{\sqrt{\text{det}\left(\textbf{A}^T \textbf{S}(\theta) \textbf{A} + \textbf{N}\right)}}.
\end{equation}
This, however, becomes intractible for modern CMB experiments as the computational expense grows as $\mathcal{O}(N_p^3)$, where $N_p$ is the number of pixels.

In the unrealistic case of isotropic noise and no applied mask, this is likelihood can be simplified and becomes computionally tractable. Using the notation that the observed beam-convolved map with noise of the CMB is $\hat{C}^{\mathrm{o}}_{\ell} = \frac{1}{2\ell+1}\sum_m d_{\ell m}d^*_{\ell m}$, and assuming isotropic white noise $N_{\ell m, \ell'm'} = N \delta_{\ell \ell'}\delta_{mm'}$, it is straightforward to show that this likelihood simplifies to
\begin{align}
    \nonumber
    \log P(\theta | \textbf{d}) = \sum_{\ell} &-\frac{2\ell+1}{2} \frac{\hat{C}^{\mathrm{o}}_{\ell}}{A_\ell^2 C^{\Lambda CDM}_{\ell}(\theta) + N}\\
    & -\frac{2\ell+1}{2} \ln \left(A_\ell^2 C^{\Lambda CDM}_{\ell}(\theta) + N \right),
\end{align}
where we have removed constant terms. Including polarization as well, this generalizes to
\begin{equation}
    \log P(\theta | \textbf{d}) = ...
\end{equation}
This will later be used as the likelihood to verify our implementation of the algorithm presented in \cite{racine:2016} with the help of Cobaya \cite{cite-cobaya}.

\subsection{Gibbs sampling}

However, a more realistic set-up includes anisotropic noise and a Galactic mask, hence we need to approach the problem differently. Using Bayes theorem, the joint posterior density $P(\theta, \textbf{s} | d)$ can be written as
\begin{align}
    \nonumber
    P(\theta, \textbf{s} | \textbf{d}) &= \frac{P(\theta, \textbf{s}, d)}{P(\textbf{d})} = P(\textbf{d} | \textbf{s})P(\textbf{s}| \theta)\frac{P(\theta)}{P(\textbf{d})}\\
    \label{eq:joint-posterior}
    &= \frac{e^{-\frac12 \left(\textbf{d}-\textbf{A}\textbf{s} \right)^T \mathbf{N}^{-1}\left(\textbf{d}-\textbf{A}\textbf{s} \right)}}{\sqrt{\mathrm{det}\left(\mathbf{N}\right)}}
    \frac{e^{-\frac12 \textbf{s}^T \mathbf{S}^{-1}\textbf{s}}}{\sqrt{\mathrm{det}\left(\mathbf{S}\right)}}\frac{P(\theta)}{P(\mathbf{d})}
\end{align}

From this joint posterior distribution, we can retrieve $P(\theta | \mathbf{d})$ by marginalizing over $\mathbf{s}$.

In the spirit of the Gibbs sampling framework of Cosmoglobe, one might think that the best approach is to Gibbs sample both the sky signal $\mathbf{s}$ and cosmological parameters $\theta$
\begin{align}
    s_{\ell m}^{i+1} &\leftarrow P(s_{\ell m} | \theta^{i}, d_{\ell m}),\\
    \label{eq:theta-gibbs}
    \theta^{i+1} &\leftarrow P(\theta | s^{i+1}, d_{\ell m}).
\end{align}
Gibbs sampling requires that we know the posterior distribution of each step. The first of these distributions is discussed in \cite{jewell2004} and \cite{wandelt2004}. As we condition on $\theta$ and $\textbf{d}$, the variance of the sky signal comes from both cosmic variance and instrumental noise. One can show that the distribution becomes
\begin{equation}
    P(\mathbf{s} | \theta, \mathbf{d}) \propto e^{-\frac12 \left(\mathbf{s} - \hat{\mathbf{s}}\right)^T \left(\mathbf{S}^{-1} - \mathbf{A}^T\mathbf{N}^{-1}\mathbf{A}\right) \left(\mathbf{s} - \hat{\mathbf{s}}\right)},
\end{equation}
where we have defined the deterministic mean field map
\begin{equation}
\label{eq:mean-field-map}
\hat{\textbf{s}} \equiv \left[\mathbf{S}^{-1} + \mathbf{A}^t \mathbf{N}^{-1}\mathbf{A} \right]^{-1} \mathbf{A} \mathbf{N}^{-1} \mathbf{d}.
\end{equation}
This is a multivariate Gaussian distribution with mean $\hat{\textbf{s}}$ and a covariance matrix $\left[\mathbf{S}^{-1} + \mathbf{A}^t \mathbf{N}^{-1}\mathbf{A} \right]^{-1}$ which can be sampled from solving the equation
\begin{equation}
    \label{eq:mapmakingeq}
    \left[\mathbf{S}^{-1} + \mathbf{A}^t \mathbf{N}^{-1}\mathbf{A} \right]\mathbf{s} = \mathbf{A} \mathbf{N}^{-1} \mathbf{d} + \mathbf{S}^{-\frac{1}{2}}\mathbf{w}_0 +\mathbf{A N}^{-\frac{1}{2}}\mathbf{w}_1,
\end{equation}
where $\mathbf{w}_0$ and $\mathbf{w}_1$ are vectors where each element is a random number drawn from $\mathcal{N}(0, 1)$. In spherical harmonics space, these two vectors must be complex\footnote{Except for $m=0$ where $w_0$ and $w_1$ are real.} with amplitude from $\mathcal{N}(0, 1)$. And the signal covariance matrix is $\mathbf{S} = \mathbf{S}(\theta^i) = C_{\ell}\left(\theta^i\right)\delta_{\ell \ell'}\delta_{mm'}$.

We decompose the sky signal into the mean field signal given in Eq.~\eqref{eq:mean-field-map} and the fluctuation part $\hat{\textbf{f}}$,
\begin{equation}
\label{eq:fluc-map}
\hat{\textbf{f}} \equiv \left[\mathbf{S}^{-1} + \mathbf{A}^t \mathbf{N}^{-1}\mathbf{A} \right]^{-1} \left(\mathbf{S}^{-\frac{1}{2}}\mathbf{w}_0 +\mathbf{A N}^{-\frac{1}{2}}\mathbf{w}_1 \right)
\end{equation}
so that $\mathbf{s} = \hat{\mathbf{s}} + \hat{\mathbf{f}}$.

If we only analyze temperature fluctuations in a setup with isotropic noise and no mask, this can be solved exactly:
\begin{align}
    \hat{s}_{\ell m} &= d_{\ell m}\frac{A_{\ell}C_{\ell}}{N_\ell + A_{\ell}^2C_{\ell}},\\
    \hat{f}_{\ell m} &= w_{0\ell m}\frac{N_{\ell}\sqrt{C_{\ell}}}{N_\ell + A_{\ell}^2C_{\ell}}+w_{1\ell m}\frac{\sqrt{N_{\ell}}A_{\ell}C_\ell}{N_\ell + A_{\ell}^2C_{\ell}}.
\end{align}
In a more realistic scenario with anisotropic noise and masking, Eq.~\eqref{eq:mapmakingeq} becomes a computationally hard equation to solve. In Commander3 it is solved by the method of Conjugant Gradient which is the slowest part of the sampling process.

In Appendix A, we show how this equation can be simplified for a constant latitude mask with isotropic noise. We will use this method to verify our algorithm implementation in Commander later.

The second step of the Gibbs sampling in Eq.~\eqref{eq:theta-gibbs} can be sampled by an inverse Wishart ditribution, but as we will not be using this step further in this work, we will refer readers to Ref.~\cite{}.

The Gibbs sampling method works well in high signal-to-noise regions, but performs poorly in the opposite limit. This can be understood by Eq.~\eqref{eq:fluc-map} when we have high instrumental noise, $\mathbf{N} \rightarrow \infty$, then $s_{\ell m} \rightarrow \sqrt{C_{\ell}} w_{0\ell m}$. But since we don't know $s_{\ell m}$, we also dont know $C_\ell$ and we get a strong degeneracy between the two. Gibbs sampling is well-known of performing poorly for strongly correlated variables as you can not move diagonally in parameter space from one end of the joint posterior distribution to the other.

\subsection{Joint sampling}

\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{figures/parameter-estimation.jpg}
    \label{fig:illustration}
	\caption{Illustration of consequetive samples of the Gibbs sampler and the method of \cite{racine:2016}. The Gibbs sampler perform poorly in the low signal-to-noise regime as it requires a much larger number of samples to explore the posterior distribution as compared to the high signal-to-noise region. The joint sampler in the lower panels performs well in both regimes as it allows the next sample to move diagonally in parameter space when we sample $\theta$, which yields $C_\ell(\theta)$ in the figure.}
\end{figure}

A solution to the poor correlation length of the Gibbs sampling in low signal-to-noise regions was proposed by \cite{jewell:2009} further developed in \cite{racine:2016}. The authors suggested to use a Metropolis-Hasting sampler with a general proposal rule for $\theta$ and a rescaling of the fluctutation term of the sky signal. This allows the move diagonally in parameter space and more efficiently explore the full joint posterior distribution, as depicted in Fig.~\ref{fig:illustration}. In other words, one would perform
\begin{align}
    \theta^{i+1} 
 &\leftarrow w(\theta |\theta^i)\\
    s_{\ell m}^{i+1} &\leftarrow P(s_{\ell m} | \theta^{i+1}, d_{\ell m}),
\end{align}
for each Gibbs iteration, where the arrow denotes drawing a sample from the distribution on the right-hand side. $w(\theta |\theta^i)$ is the proposal distribution of the cosmological parameters. We use a multivariate Gaussian,
\begin{equation}
w(\theta |\theta^i) = e^{-\frac12 \left(\theta - \theta^i \right)^T C_{\theta}^{-1}\left(\theta - \theta^i \right)}.
\end{equation}
For optimal chain convergence, the proposal variance $C_{\theta}$ should resemble the posterior distribution. The proposal variance we use is created from the samples of an earlier chain created with a diagonal proposal matrix.

Following \cite{racine:2016} we make a slight altercation. We scale the fluctuation map of the last accepted sample.
\begin{equation}
    \hat{f}_{\ell m}^{\textrm{scaled},\, i+1} = \left(\textbf{C}^{i+1}_{\ell}\right)^{1/2}\left(\textbf{C}^{i}_{\ell}\right)^{-1/2} \hat{f}_{\ell m}^{i},
\end{equation}
so that the map of sample $i+1$ becomes
\begin{equation}
    s^{i+1}_{\ell m} = \hat{s}_{\ell m}^{i+1} + \left(\textbf{C}^{i+1}_{\ell}\right)^{1/2}\left(\textbf{C}^{i}_{\ell}\right)^{-1/2} \hat{f}_{\ell m}^{i}.
\end{equation}
Here,
\begin{equation}
\textbf{C}_{\ell} = \begin{bmatrix}
C^{TT}_\ell & C^{TE}_\ell & 0\\
C^{TE}_\ell & C^{EE}_\ell & 0\\
0 & 0 & C^{BB}_\ell
\end{bmatrix},
\end{equation}
Here, we have set the parity-odd power spectra to zero, i.e. $C^{EB}_\ell =C^{TB}_\ell = 0$ as predicted by \LCDM.

Hence, instead of solving Eq.~\eqref{eq:fluc-map} for a new fluctuation map for sample $i+1$, we scale the fluctuation map of the previous sample. If sample $i+1$ is accepted, then we calculate $f^{i+1}$ from Eq.~\eqref{eq:fluc-map} which will be used to find the scaled fluctuation map of the enxt sample, $\hat{f}_{\ell m}^{\textrm{scaled},\, i+2}$.

The acceptance rate for this proposal was calculated in \cite{racine:2016} to be
\begin{equation}
    \label{eq:acceptance-rate}
    A = \mathrm{min}\left[1, \frac{\pi(\theta^{i+1})}{\pi(\theta^i)} \frac{w(\theta^{i} |\theta^{i+1})}{w(\theta^{i+1} |\theta^i) }\frac{P(\theta^{i+1})}{P(\theta^i)} \right].
\end{equation}
Here, $P(\theta)$ is the prior on $\theta$ and
\begin{align}
    \nonumber
    \pi(\theta^{i}) = \mathrm{exp}\bigg[&-\frac12 \left(d-A\hat{s}^i\right)^T \textbf{N}^{-1}\left(d-A\hat{s}^i\right)\\
    &-\frac12 \hat{s}^{i,T} \textbf{S}^{i, -1}\hat{s}^i -\frac12 \hat{f}^{i, T}A^T\textbf{N}^{-1} A\hat{f}^i\bigg],
\end{align}
where we have omitted the $\theta^i$ dependence of $\hat{s}^i$, $\hat{f}^i$ and $S^i$. Our proposal matrix for the cosmological parameters is symmetric, $w(\theta^{i} |\theta^{i+1}) = w(\theta^{i+1} |\theta^{i})$, and hence we can remove them from Eq.~\eqref{eq:acceptance-rate}.

Again, the acceptance rate will use the scaled fluctuation term, $f_{\ell m}^{\textrm{scaled}, i+1}$, for sample $i+1$ instead of the calculated fluctuation term in Eq.~\eqref{eq:mapmakingeq}. Sample $i$ however, will use the fluctuation solution to Eq.~\eqref{eq:mapmakingeq}.

The algorithm can be broken down into these steps:
\begin{itemize}
    \item 1. Start with an initial value $\theta^0$. From that, calculate the power spectra $S^0$, the mean-field map $\hat{s}^0$ and the fluctuation map $\hat{f}^0$ from the cosmological parameters.
    \item 2. Pick a new cosmological parameter sample, $\theta^{i+1}$. Calculate $S^{i+1}$, $\hat{s}^{i+1}$ and the \textit{scaled} fluctuation term $f_{\ell m}^{\textrm{scaled}, i+1}$.
    \item 3. Calculate the acceptance term of Eq.~\ref{eq:acceptance-rate}, and accept/reject according to the regular Metropolis-Hasting rule.
    \item 4. If the sample is accepted, then calculate $f_{\ell m}^{i+1}$. This term will in the next iteration become $f_{\ell m}^{i}$ which will appear in the acceptance probability and the equation for $f_{\ell m}^{\textrm{scaled}, i+1}$. The fluctuation map is not necessary to calculate if the sample is discarded.
    \item 5. Iterate 2-4.
\end{itemize}

In this work, we sample the 6 $\Lambda$CDM parameters, i.e. $\theta=(\Omega_{\textrm{b}}h^2, \Omega_{\textrm{CDM}}h^2, H_0, \tau, A_s, n_s)$. Here, $\Omega_\mathrm{b}$ and $\Omega_\mathrm{CDM}$ are the current density of baryonic and cold dark matter, respectively. $H_0$ si the Hubble constant today, while $h$ is the normalized Hubble constant, $h=\frac{H_0}{100\,\mathrm{km s}^{-1} \mathrm{MPc}^{-1}}$. $\tau$ is the optical depth at reionization, $A_s$ is the amplitude and $n_s$ is the tilt of the scalar primordial power spectrum.


\section{Results}
\label{sec:results}

This work aims to implement the algorithm into the Commander framework as a part of the full Gibbs sampling process alongside sampling of instrumental and astrophysical parameter in future work.

To verify the implementation, we also created a Python script that samples cosmological parameters on a CMB simulation with isotropic noise and a constant latitude mask. We show how we calculate an analytic expression for $N^{-1}_{\ell m, \ell' m'}$ in Appendix A, and how that simplifies matrix equations such as the map making equation and acceptance rate.

We created 2 sets of CMB simulations: One with isotropic noise and one with anisotropic noise using a realization of a randomly picked RMS noise map of the 70\,GHz from the official BeyondPlanck chain. Both simulations are created using $N_{\textrm{side}}=512$ and the PR4 70\,GHz beams.

First, we run the isotropic noise simulation without a mask in Cobaya, Python and Commander to make sure the three implementations agree with each other as this case can be solved exactly using the likelihood presented in Section \ref{sec:exact-likelihood}. Fig.~\ref{fig:nomask} shows the posterior distribution of the cosmological parameters from 50 000 samples each of Commander, Python and Cobaya, and we find excellent agreement between the three implementations.

Then we test the algorithm with a constant latitude mask. $\textbf{N}$ is no longer diagonal, and Cobaya will not be able to capture all the information any longer. We, therefore, sample it with Python and Commander. This works.

We then turn to the realistic case: we use anisotropic noise and a realistic mask. Our Python script can not sample this as $\textbf{N}$ is highly complex and so solving the map equation is computationally hard. To solve this equation, we, therefore, rely on the conjugate gradient method in Commander.

\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{figures/dist_posterior_no_mask.pdf}
	\caption{\label{fig:nomask}Parameter estimation on a CMB realization with isotropic noise. We use $N_{\mathrm{side}}=512$ and the beam convolve using the beam window functions of 70\,GHz band of Planck. No mask is applied.}
\end{figure}
\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{figures/dist_posterior_10_mask.pdf}
	\caption{Cosmological parameter estimation on same simulation as in Fig.~\ref{fig:nomask} but a constant latitude mask is applied so that the sky fraction is 90\%.}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{figures/sigma_ell.pdf}
	\caption{\label{fig:sigma_ell}The power spectra for a random sample for the 70\,GHz case compared to the theoretical CAMB power spectra.}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{figures/auto_correlation.pdf}
	\caption{Auto correlations of some cosmological parameters.}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{figures/run_time.pdf}
	\caption{CPU-hours}
\end{figure}

\section{Conclusions}
\label{sec:conclusions}

We have shown that the algorithm presented in \cite{racine:2016} works well in the Commander framework for anisotropic noise and mask.

\bibliographystyle{../common/aa}

\bibliography{../common/Planck_bib, ../common/CG_bibliography}

\appendix

\section{Analytic expression for a constant latitude mask}
\label{sec:appendix}


The goal of this appendix is to show how we can calculate $N_{\ell m, \ell' m'}^{-1}$ analytically for a constant latitude mask and uniform noise, and how this expression makes the map making equation computationally fast to solve. The noise can be written as this in pixel space:
$$
\left(N^{-1} \right)_{pp'} = \frac{N_{\mathrm{pix}}}{\sigma^2} \delta_{pp'} H(|\theta(p) -\pi/2|-b).
$$
where $H$ is the Heavyside function, meaning that we mask every pixel $p$ where $|\theta(p) -\pi/2| < b$ for some latitude $b$ in radians. For a masked pixel, $\left(N^{-1} \right)_{pp}=0$ which means that $N_{pp} = \infty$ for that pixel, as we want.

Using that
$$
\left(N^{-1}\right)_{pp'} = \sum_{\ell m}\sum_{\ell' m'} \left(N^{-1}\right)_{\ell m, \ell'm'} Y_{\ell m}\left(p\right)Y^*_{\ell' m'}\left(p'\right),
$$
where $Y_{\ell m}\left(p\right) = Y_{\ell m}\left(\hat{n}(p)\right)$ and $\hat{n}(p)$ are the spherical coordinates for pixel $p$, we can transform to spherical harmonics space,
\begin{align}
\nonumber
\left(N^{-1}\right)_{\ell m, \ell' m'} &= \sum_{p p'}\left(N^{-1}\right)_{pp'}Y^{*}_{\ell m}(p)Y_{\ell' m'}(p')\\
\nonumber
&= \frac{N_{\mathrm{pix}}}{\sigma^2}\sum_{p p'} Y^{*}_{\ell m}(p)Y_{\ell' m'}(p') \delta_{pp'} H(|\theta -\pi/2|-b)\\
\nonumber
&= \frac{N_{\mathrm{pix}}}{\sigma^2}\sum_{p } Y^{*}_{\ell m}(p)Y_{\ell' m'}(p) H(|\theta -\pi/2|-b)\\
&= \frac{N_{\mathrm{pix}}}{\sigma^2}\sum_p \Tilde{Y}_{\ell m}\Tilde{Y}_{\ell' m'} e^{-i(m-m')\phi} H(|\theta -\pi/2|-b).
\end{align}
Here, we used that $Y_{\ell m}(p) = \tilde{Y}_{\ell m} e^{im\phi}$ where it is implied that $\tilde{Y}_{\ell m}=\tilde{Y}_{\ell m}(\theta)$, and $\theta$ and $\phi$ are functions of $p$.

We now take the limit where there is a large amount of pixels with equal surface area each. In this limit, we change the sum into an integration where we account for the number of pixels per area element
\begin{equation}
\sum_p \rightarrow \frac{N_{\mathrm{pix}}}{4\pi}\int d\Omega  = \frac{N_{\mathrm{pix}}}{4\pi}\int_{0}^{2\pi} d\phi \int_{0}^{\pi} d\theta \sin(\theta).
\end{equation}
This gives us in spherical coordinates
\begin{align}
\nonumber
\left(N^{-1}\right)_{\ell m, \ell' m'} &= \frac{N_{\mathrm{pix}}^2}{4\pi \sigma^2}\int_{0}^{2\pi} d\phi \int_{0}^{\pi} d\theta \sin(\theta)\tilde{Y}_{\ell m}  \tilde{Y}_{\ell' m'}  e^{-i(m-m')\phi}
\\
\nonumber
&\cdot H(|\theta -\pi/2|-b)\\
\nonumber
&= \frac{N_{\mathrm{pix}}^2}{2\sigma^2} \delta_{mm'}\int_{0}^{\pi} d\theta \sin(\theta)\tilde{Y}_{\ell m}  \tilde{Y}_{\ell' m'} H(|\theta -\pi/2|-b)\\
\nonumber
&= \frac{N_{\mathrm{pix}}^2}{2\sigma^2} \delta_{mm'}\\
&\cdot \left(\int_{0}^{\pi/2-b} d\theta \sin(\theta) \tilde{Y}_{\ell m}  \tilde{Y}_{\ell' m'}+\int_{\pi/2+b}^{\pi} d\theta \sin(\theta)\tilde{Y}_{\ell m}  \tilde{Y}_{\ell' m'}\right).
\end{align}
Writing the above equation in terms of Legendre polynomials $P_{\ell m}(\cos(\theta)))$, we have
$\Tilde{Y}_{\ell m} = \Delta_{\ell m}P_{\ell m}(\cos(\theta)))$, where ${\Delta_{\ell m}=(-1)^m \sqrt{\frac{2\ell+1}{4\pi}\frac{(\ell - m)!}{(\ell+m)!}}}$.
 Writing $x=\cos(\theta)$, we know that Legendre polynomials $P_{\ell m}(x)$ are either symmetric or antisymmetric in $x\rightarrow-x$. $P_{\ell m}(x)$ is symmetric in $x \rightarrow -x$ when $\ell+m$ = even and antisymmetric when $\ell+m$ = odd. Since $m=m'$, we note that the two integrals cancel each other if $\ell+\ell' =$ odd. We, therefore, only get non-zero elements when $\ell + \ell' =$ even, for which the two integrals are equal. Hence, for $\ell + \ell'=$ even, we get
\begin{align}
\nonumber
\left(N^{-1}\right)_{\ell m, \ell' m'} &= \frac{N_{\mathrm{pix}}^2}{\sigma^2} \delta_{mm'}\int_{0}^{\pi/2-b} d\theta \sin(\theta)\Tilde{Y}_{\ell m}(\theta)\Tilde{Y}_{\ell' m'}(\theta)\\
\label{eq:finished_n_inv}
&=\frac{N_{\mathrm{pix}}^2}{\sigma^2} \delta_{mm'}\int_{\sin(b)}^{1} dx \, \Tilde{Y}_{\ell m}(\arccos(x)) \Tilde{Y}_{\ell' m}(\arccos(x)).
\end{align}
This integral can be solved numerically by gridding $x$, and the spherical harmonics where the phase factor is removed can be calculated in Python using a library like ...

Since the azimutally symmetric Galactic mask used for this work is $\sin(b) = 0.1$, we require much fewer grid points for $x$ if we use the following identity for $\ell+\ell' = $ even:
\begin{align}
&\delta_{mm'} \int_{\sin(b)}^{1} dx \, \Tilde{Y}_{\ell m}(\arccos(x)) \Tilde{Y}_{\ell' m}(\arccos(x)) = \\
\frac{1}{4\pi}\delta_{\ell \ell'}\delta_{m m'} - &\delta_{mm'} \int_{0}^{\sin(b)} dx \, \Tilde{Y}_{\ell m}(\arccos(x)) \Tilde{Y}_{\ell' m}(\arccos(x)),
\end{align}
which comes from the orthonormality condition for spherical harmonics. We now only need to grid $x$ in the interval $0\leq x \leq \sin(b) = 0.1$ for this work.

Since $N^{-1}_{\ell m, \ell' m'} \propto \delta_{m m'}$, we get simplified matrix expressions. Imagine multiplying the matrix $\textbf{N}^{-1} = N^{-1}_{\ell m, \ell' m'}$ with the vector $\textbf{b} = b_{\ell m}$
\begin{align}
\textbf{N}^{-1} \cdot \textbf{b} &= \sum_{\ell' m'}\left(N^{-1}\right)_{\ell m, \ell' m'}b_{\ell' m'} = \sum_{\ell'}\left(N^{-1}\right)_{\ell m, \ell' m}b_{\ell' m}\\
&= \sum_{\ell' }\left(N^{-1}\right)^{(m)}_{\ell, \ell'}b^{(m)}_{\ell'}.
\end{align}
To solve the map-making equation, we get a matrix equation for each $0 \leq m \leq \ell_{\mathrm{max}}$. This gives us $\ell_{\textrm{max}}+1$ number of matrix equations where the dimensions of the matrices are maximally $\ell_{\textrm{max}} \times \ell_{\textrm{max}}$. This is numerically much quicker than inverting the full $(\ell_{\textrm{max}})^2 \times (\ell_{\textrm{max}})^2$ matrix once.


\end{document}
